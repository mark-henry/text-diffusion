# BART Denoising Training Journal

## 2025-06-24 - BART-based denoising architecture

### Architecture Overview

**BART Diffusion Model for Text Generation**
- **Frozen Components**: BART embedding layers (39,393,024 parameters) for latentâ†’embedding conversion
- **Trainable Components**: BART transformer layers (42,527,232 parameters) for denoising, instead of a unet
- **Objective**: xâ‚€ Prediction following Li et al. 2022 - Direct prediction of clean latents `L = ||f_Î¸(x_t, t) - x_0||Â²`
  - Unlike typical diffusion models that predict noise, this model directly predicts the original clean latents regardless of noise level
- **Time Encoding**: Sinusoidal embeddings with learned adaptive scaling for temporal conditioning

### Hyperparameters

**Model Configuration**:
- Model: BartDiffusionLM with BART-based denoising
- Dataset: WikiText-2
- Architecture: `bart_encoder_with_time_injection`
- Time embedding dimension: 256
- Learned time-based latent scaling: Enabled

**Training Configuration**:
- Batch size: 96
- Learning rate: 5e-05
- Epochs: 40
- Max sequence length: 64
- Optimizer: AdamW
- Weight decay: 0.01
- Gradient clipping: 1.0
- Mixed precision: Enabled

**Diffusion Parameters**:
- Noise scheduler: Cosine
- Timesteps: 2,000
- Schedule parameter (s): 0.008
- Loss function: xâ‚€ prediction objective

### Final Results after 40 Epochs

**Loss Metrics**:
- Final training loss: 0.4148
- Final validation loss: 0.3929
- **Best validation loss: 0.3926** â­

**Quality Metrics**:
- Final training cosine similarity: 0.8413
- **Final validation cosine similarity: 0.8534** ðŸŽ¯
- **Final magnitude ratio: 0.8466** (major improvement from ~0.3 in previous runs)

**Training Efficiency**:
- Total training time: 3,885.57 seconds (~1.08 hours)
- Average time per epoch: ~97 seconds
- GPU utilization: CUDA-accelerated

### Key Achievements

1. **Magnitude Recovery**: Achieved 84.66% magnitude ratio (vs ~30% in previous attempts)
2. **High Cosine Similarity**: 85.34% similarity on validation set (up from ~35% with a unet)
3. **Stable Training**: Consistent improvement across all 40 epochs with early stopping patience
4. **Effective Architecture**: xâ‚€ prediction objective with learned time scaling proved highly effective

### Notes

This represents a significant breakthrough in addressing the magnitude under-prediction issue that plagued earlier training runs. The combination of moving from a unet to a transformer architecture, and direct xâ‚€ prediction has successfully maintained both semantic coherence (cosine similarity) and magnitude fidelity.

### Results

The numbers are a big win but this model does not produce recognizably English results. Even at low timesteps like 0 or 1, the model takes in sample text and puts out garbage with low cosine similarity to the original ("cos" below):

```
â° t= 0 (  0.0% noise):
   ðŸŸ¢ Original:      Roman and Greek sources nowhere report Nero 's alleged trip to Jerusalem or his ...
   ðŸ”„ Reconstructed: ï¿½SOURCE,A dispensaryNYSEBornMeetPokÃ©monTicketsEnlargeNASAMayLearyJosephGovernBot...
   ðŸ“Š cos=0.564, mag=2.535, mse=0.1972
```

# 2025-06-24 

Unlocked the embedding weights and reformulated the loss function into the three-part loss described in Li, Thickstun et al 2022.

ðŸ“ˆ Training Summary:
   Total Epochs: 40
   Total Time: 5398.17s
   Final Train Loss: 6.7145
   Final Val Loss: 7.0019
   Best Val Loss: 6.996714
   Final Train Cosine Sim: 0.9519
   Final Val Cosine Sim: 0.9695
   Final Magnitude Ratio: 1.1343
   Average Denoising Improvement: 0.5011
Diffusion-LM training complete!

Magnitude ratio was a bit high. Unfortunately the cosine similarity seems to have decreased over the course of the run. Understandable; we're making the embeddings more separated and meaningful as training progresses.

This model is not able to predict step-0 or step-1 denoised:
```
ðŸŸ¢ ORIGINAL: On May 13 , 2014 , On the band 's official Facebook page , they released the official announcement of when the band 's new album Evolution will hit stores . The album is set for release July 22 , 2014...

ðŸ”´ t=   1 (  0.0% noise, cos=0.027, mag=2.533):  nonprofits nonprofits nonprofitsivistivistivist nonprofitsivist nonprofits nonprofits :) nonprofits :) :) nonprofitsivist :) :) :)ivist nonprofits :)ivist :) nonprofits nonprofits pH :) :) pH :) nonprofits pH nonprofits :) pH nonprofits nonprofits nonprofit :) :) nonprofit :) nonprofits nonprofit nonprofits :) nonprofit nonprofits nonprofits clinically :) :) Debian :) :) clinically nonprofits :) Debian nonprofits :) clinically :) nonprofits clinically nonprofits nonprofits Debian :) nonprofits Debian nonprofits nonprofits charity :) :) charity :) nonprofits charity nonprofits :) charity nonprofits nonprofits ;) :) :) 4 :) :) (> :) :) ;) :)
```

## 2025-06-26 - First Cogent Output Breakthrough! ðŸŽ‰

### Major Milestone Achieved

**FIRST TIME GETTING COGENT OUTPUT FROM THE MODEL!** This represents a significant breakthrough after previous attempts produced garbled text or token repetition. The model now generates recognizable English text that resembles Wikipedia-style content.

### Performance Evaluation

**Validation Results**:
- **Cosine Similarity**: ~57% (56.6% average across all timesteps)
- **Magnitude Scaling**: ~0.49x (consistent scaling factor)
- **Stability**: Excellent - only 0.013 difference between low and high noise performance
- **Quality**: Fair across all timesteps (stable performance)

### Model Behavior Analysis

**Key Observations**:
1. **Generic "Wikipediaese" Output**: The model has learned to generate Wikipedia-style text that achieves ~60% similarity to any sample from the dataset. This "Wikipediaese" is themed around police and tragedy.
2. **Input-Independent Output**: The model's output does not vary significantly with input - produces similar text regardless of the original content
3. **Consistent Performance**: ~57% cosine similarity maintained across all noise levels (0% to 99.4% noise)
4. **Self-Trained Embeddings**: Successfully learned embeddings that enable coherent text generation

### Sample Output Examples

**Example 1** (Project/Memorial Text â†’ Police Investigation):
```
ðŸŸ¢ ORIGINAL: A project is underway to photograph the graves of and memorials to all service personnel from 1914 to the present day and make the images available to the public...

ðŸ”µ t=0 (0.0% noise):
However, it is possible that the police and police officers who are investigating by police and the police are investigating...
```

**Example 2** (Game Review â†’ Personal Drama):
```
ðŸŸ¢ ORIGINAL: Planet Game Boy called it one of the original Game Boy's ten "all-time classics"...

ðŸ”µ t=0 (0.0% noise):
By the time she leaves, she has been crying and crying and she has found herself crying when she reports that she has seen...
```

### Technical Insights

**Performance Metrics Summary**:
- **Semantic Preservation**: 56.6% semantic direction preservation
- **Noise Robustness**: Performance stable from 0% to 99.4% noise
- **Consistent Scaling**: 0.49x magnitude factor across all conditions
- **Text Quality**: Coherent, grammatically correct English output

### Next Steps and Priorities

1. **Improve Input Sensitivity**: Current model generates similar output regardless of input - need to increase conditional dependence on original text
2. **Target Higher Similarities**: Aim for much higher cosine similarities, especially for low-noise steps (t=0-10)
3. **Preserve Content Specificity**: Maintain semantic content from original text rather than defaulting to generic "police investigation" or "personal drama" themes
4. **Fine-tune Architecture**: Investigate why the model converges to generic Wikipedia-style content

### Significance

This represents the first successful generation of coherent English text from a diffusion model in this project. While the output is generic, it demonstrates that:
- The model architecture is fundamentally sound
- The training process successfully learned text generation
- Self-trained embeddings are working effectively
- The foundation is in place for more sophisticated content-aware generation

**Status**: ðŸŽ¯ **Breakthrough achieved** - coherent text generation established, now optimizing for input fidelity and content preservation.